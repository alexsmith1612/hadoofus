language: c
addons:
  apt:
    packages:
      - protobuf-c-compiler
      - libprotobuf-c-dev
      - libprotobuf-c1
      - libsasl2-dev
      - libsasl2-2
      - check

install:
  # Only download hadoop if we're going to test against the Hadoop CLI MiniCluster
  - |
    if [ "$CK_RUN_SUITE" = "" ] ; then
      wget http://www.trieuvan.com/apache/hadoop/common/hadoop-3.1.3/hadoop-3.1.3.tar.gz \
      && tar -xzf hadoop-3.1.3.tar.gz \
      && sudo mv hadoop-3.1.3 /usr/local/hadoop
    fi

env:
  global:
    CK_VERBOSITY: verbose
    HDFS_TEST_NODE_ADDRESS: localhost
    HDFS_TEST_NODE_PORT: 9000
    HDFS_TEST_USER: travis
    HADOOP_ROOT_LOGGER: WARN,DRFA # decrease cluster's log level and don't print to console

# Travis doesn't allow dist to be a sequence, so in order to test on both
# Ubuntu 16.04 and 18.04 we need to explicitly describe the build matrix
jobs:
  include:
    - dist: xenial
      compiler: gcc
      arch: amd64
      env:
        # gcc on 16.04 doesn't support -Wnull-dereference, so clear WARNS_NEW
        WARNS_NEW:

    - dist: xenial
      compiler: clang
      arch: amd64

    - dist: bionic
      compiler: gcc
      arch: amd64

    - dist: bionic
      compiler: clang
      arch: amd64

    # arm64 allows us to test the armv8 hardware crc32c implementation
    - dist: xenial
      compiler: gcc
      arch: arm64
      env:
        # gcc on 16.04 doesn't support -Wnull-dereference, so clear WARNS_NEW
        WARNS_NEW:
        # gcc has a false positive for __has_attribute(ifunc) on arm64 for
        # Ubuntu 16.04, so force use of the non-ifunc fallback code
        CFLAGS: -DNO_IFUNC
        # don't spin up the cluster and only run the "unit" test suite on arm64
        CK_RUN_SUITE: unit

    - dist: xenial
      compiler: clang
      arch: arm64
      env:
        # don't spin up the cluster and only run the "unit" test suite on arm64
        CK_RUN_SUITE: unit

    - dist: bionic
      compiler: gcc
      arch: arm64
      env:
        # gcc has a false positive for __has_attribute(ifunc) on arm64 for
        # Ubuntu 18.04, so force use of the non-ifunc fallback code
        CFLAGS: -DNO_IFUNC
        # don't spin up the cluster and only run the "unit" test suite on arm64
        CK_RUN_SUITE: unit

    - dist: bionic
      compiler: clang
      arch: arm64
      env:
        # don't spin up the cluster and only run the "unit" test suite on arm64
        CK_RUN_SUITE: unit

    # s390x allows us to test the big endian software crc32c implementation
    - dist: xenial
      compiler: gcc
      arch: s390x
      env:
        # gcc on 16.04 doesn't support -Wnull-dereference, so clear WARNS_NEW
        WARNS_NEW:
        # gcc does not have -mtune=generic on s390x, so clear ARCH_CFLAGS
        ARCH_CFLAGS:
        # don't spin up the cluster and only run the "unit" test suite on s390x
        CK_RUN_SUITE: unit

    - dist: xenial
      compiler: clang
      arch: s390x
      env:
        # clang's -fstack-protector does not properly link on s390x xenial
        CFLAGS: -fno-stack-protector
        # don't spin up the cluster and only run the "unit" test suite on s390x
        CK_RUN_SUITE: unit

    - dist: bionic
      compiler: gcc
      arch: s390x
      env:
        # gcc does not have -mtune=generic on s390x, so clear ARCH_CFLAGS
        ARCH_CFLAGS:
        # don't spin up the cluster and only run the "unit" test suite on s390x
        CK_RUN_SUITE: unit

    - dist: bionic
      compiler: clang
      arch: s390x
      env:
        # don't spin up the cluster and only run the "unit" test suite on s390x
        CK_RUN_SUITE: unit

script:
  - make -j$(nproc) all
  - |
    # Only spin up the minicluster if we're testing against it (and if we downloaded it)
    if [ "$CK_RUN_SUITE" = "" ] ; then
      /usr/local/hadoop/bin/mapred minicluster -nomr -format -nnport $HDFS_TEST_NODE_PORT -datanodes 4 &
      CLUSTER_PID=$!
      # Wait until the cluster is up by polling the namenode port with netcat
      cnt=0
      while ! nc -vz localhost $HDFS_TEST_NODE_PORT ; do
        echo "$cnt"
        cnt=$((cnt + 1))
        if [ "$cnt" -gt "5" ] ; then exit 1; fi
        sleep 5;
      done
      # Wait a bit longer to ensure the rest of the cluster finalized setup
      sleep 10
    fi
  - make test
  - if [ "$CK_RUN_SUITE" = "" ] ; then kill $CLUSTER_PID; fi
